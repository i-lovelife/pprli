{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import imageio\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32') / 255 - 0.5\n",
    "x_test = x_test.astype('float32') / 255 - 0.5\n",
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)\n",
    "img_dim = x_train.shape[1]\n",
    "\n",
    "\n",
    "z_dim = 256 # 隐变量维度\n",
    "alpha = 0.5 # 全局互信息的loss比重\n",
    "beta = 1.5 # 局部互信息的loss比重\n",
    "gamma = 0.01 # 先验分布的loss比重\n",
    "\n",
    "\n",
    "# 编码器（卷积与最大池化）\n",
    "x_in = Input(shape=(img_dim, img_dim, 3))\n",
    "x = x_in\n",
    "\n",
    "for i in range(3):\n",
    "    x = Conv2D(z_dim / 2**(2-i),\n",
    "               kernel_size=(3,3),\n",
    "               padding='SAME')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "feature_map = x # 截断到这里，认为到这里是feature_map（局部特征）\n",
    "feature_map_encoder = Model(x_in, x)\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    x = Conv2D(z_dim,\n",
    "               kernel_size=(3,3),\n",
    "               padding='SAME')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "x = GlobalMaxPooling2D()(x) # 全局特征\n",
    "\n",
    "z_mean = Dense(z_dim)(x) # 均值，也就是最终输出的编码\n",
    "z_log_var = Dense(z_dim)(x) # 方差，这里都是模仿VAE的\n",
    "\n",
    "\n",
    "encoder = Model(x_in, z_mean) # 总的编码器就是输出z_mean\n",
    "\n",
    "\n",
    "# 重参数技巧\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    u = K.random_normal(shape=K.shape(z_mean))\n",
    "    return z_mean + K.exp(z_log_var / 2) * u\n",
    "\n",
    "\n",
    "# 重参数层，相当于给输入加入噪声\n",
    "z_samples = Lambda(sampling)([z_mean, z_log_var])\n",
    "prior_kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var))\n",
    "\n",
    "\n",
    "# shuffle层，打乱第一个轴\n",
    "def shuffling(x):\n",
    "    idxs = K.arange(0, K.shape(x)[0])\n",
    "    idxs = K.tf.random_shuffle(idxs)\n",
    "    return K.gather(x, idxs)\n",
    "\n",
    "\n",
    "# 与随机采样的特征拼接（全局）\n",
    "z_shuffle = Lambda(shuffling)(z_samples)\n",
    "z_z_1 = Concatenate()([z_samples, z_samples])\n",
    "z_z_2 = Concatenate()([z_samples, z_shuffle])\n",
    "\n",
    "# 与随机采样的特征拼接（局部）\n",
    "feature_map_shuffle = Lambda(shuffling)(feature_map)\n",
    "z_samples_repeat = RepeatVector(4 * 4)(z_samples)\n",
    "z_samples_map = Reshape((4, 4, z_dim))(z_samples_repeat)\n",
    "z_f_1 = Concatenate()([z_samples_map, feature_map])\n",
    "z_f_2 = Concatenate()([z_samples_map, feature_map_shuffle])\n",
    "\n",
    "\n",
    "# 全局判别器\n",
    "z_in = Input(shape=(z_dim*2,))\n",
    "z = z_in\n",
    "z = Dense(z_dim, activation='relu')(z)\n",
    "z = Dense(z_dim, activation='relu')(z)\n",
    "z = Dense(z_dim, activation='relu')(z)\n",
    "z = Dense(1, activation='sigmoid')(z)\n",
    "\n",
    "GlobalDiscriminator = Model(z_in, z)\n",
    "\n",
    "z_z_1_scores = GlobalDiscriminator(z_z_1)\n",
    "z_z_2_scores = GlobalDiscriminator(z_z_2)\n",
    "global_info_loss = - K.mean(K.log(z_z_1_scores + 1e-6) + K.log(1 - z_z_2_scores + 1e-6))\n",
    "\n",
    "\n",
    "# 局部判别器\n",
    "z_in = Input(shape=(None, None, z_dim*2))\n",
    "z = z_in\n",
    "z = Dense(z_dim, activation='relu')(z)\n",
    "z = Dense(z_dim, activation='relu')(z)\n",
    "z = Dense(z_dim, activation='relu')(z)\n",
    "z = Dense(1, activation='sigmoid')(z)\n",
    "\n",
    "LocalDiscriminator = Model(z_in, z)\n",
    "\n",
    "z_f_1_scores = LocalDiscriminator(z_f_1)\n",
    "z_f_2_scores = LocalDiscriminator(z_f_2)\n",
    "local_info_loss = - K.mean(K.log(z_f_1_scores + 1e-6) + K.log(1 - z_f_2_scores + 1e-6))\n",
    "\n",
    "# 用来训练的模型\n",
    "model_train = Model(x_in, [z_z_1_scores, z_z_2_scores, z_f_1_scores, z_f_2_scores])\n",
    "model_train.add_loss(alpha * global_info_loss + beta * local_info_loss + gamma * prior_kl_loss)\n",
    "model_train.compile(optimizer=Adam(1e-3))\n",
    "\n",
    "model_train.fit(x_train, epochs=50, batch_size=64)\n",
    "model_train.save_weights('total_model.cifar10.weights')\n",
    "\n",
    "\n",
    "# 输出编码器的特征\n",
    "zs = encoder.predict(x_train, verbose=True)\n",
    "zs.mean() # 查看均值（简单观察先验分布有没有达到效果）\n",
    "zs.std() # 查看方差（简单观察先验分布有没有达到效果）\n",
    "\n",
    "\n",
    "# 随机选一张图片，输出最相近的图片\n",
    "# 可以选用欧氏距离或者cos值\n",
    "def sample_knn(path):\n",
    "    n = 10\n",
    "    topn = 10\n",
    "    figure1 = np.zeros((img_dim*n, img_dim*topn, 3))\n",
    "    figure2 = np.zeros((img_dim*n, img_dim*topn, 3))\n",
    "    zs_ = zs / (zs**2).sum(1, keepdims=True)**0.5\n",
    "    for i in range(n):\n",
    "        one = np.random.choice(len(x_train))\n",
    "        idxs = ((zs**2).sum(1) + (zs[one]**2).sum() - 2 * np.dot(zs, zs[one])).argsort()[:topn]\n",
    "        for j,k in enumerate(idxs):\n",
    "            digit = x_train[k]\n",
    "            figure1[i*img_dim: (i+1)*img_dim,\n",
    "                   j*img_dim: (j+1)*img_dim] = digit\n",
    "        idxs = np.dot(zs_, zs_[one]).argsort()[-n:][::-1]\n",
    "        for j,k in enumerate(idxs):\n",
    "            digit = x_train[k]\n",
    "            figure2[i*img_dim: (i+1)*img_dim,\n",
    "                   j*img_dim: (j+1)*img_dim] = digit\n",
    "    figure1 = (figure1 + 1) / 2 * 255\n",
    "    figure1 = np.clip(figure1, 0, 255)\n",
    "    figure2 = (figure2 + 1) / 2 * 255\n",
    "    figure2 = np.clip(figure2, 0, 255)\n",
    "    imageio.imwrite(path+'_l2.png', figure1)\n",
    "    imageio.imwrite(path+'_cos.png', figure2)\n",
    "\n",
    "\n",
    "sample_knn('test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
